{"articles":[{"id":1,"title":"A General Framework for Constrained Bayesian Optimization using Information-based Search","url":"https://www.researchgate.net/publication/285458515_A_General_Framework_for_Constrained_Bayesian_Optimization_using_Information-based_Search","abstraction":"We present an information-theoretic framework for solving global black-box optimization problems that also have black-box constraints. Of particular interest to us is to efficiently solve problems with decoupled constraints, in which subsets of the objective and constraint functions may be evaluated independently. For example, when the objective is evaluated on a CPU and the constraints are evaluated independently on a GPU. These problems require an acquisition function that can be separated into the contributions of the individual function evaluations. We develop one such acquisition function and call it Predictive Entropy Search with Constraints (PESC). PESC is an approximation to the expected information gain criterion and it compares favorably to alternative approaches based on improvement in several synthetic and real-world problems. In addition to this, we consider problems with a mix of functions that are fast and slow to evaluate. These problems require balancing the amount of time spent in the meta-computation of PESC and in the actual evaluation of the target objective. We take a bounded rationality approach and develop a partial update for PESC which trades off accuracy against speed. We then propose a method for adaptively switching between the partial and full updates for PESC. This allows us to interpolate between versions of PESC that are efficient in terms of function evaluations and those that are efficient in terms of wall-clock time. Overall, we demonstrate that PESC is an effective algorithm that provides a promising direction towards a unified solution for constrained Bayesian optimization."},{"id":2,"title":"Parallel Predictive Entropy Search for Batch Global Optimization of Expensive Objective Functions","url":"https://www.researchgate.net/publication/284579255_Parallel_Predictive_Entropy_Search_for_Batch_Global_Optimization_of_Expensive_Objective_Functions","abstraction":"We develop parallel predictive entropy search (PPES), a novel algorithm for Bayesian optimization of expensive black-box objective functions. At each iteration, PPES aims to select a batch of points which will maximize the information gain about the global maximizer of the objective. Well known strategies exist for suggesting a single evaluation point based on previous observations, while far fewer are known for selecting batches of points to evaluate in parallel. The few batch selection schemes that have been studied all resort to greedy methods to compute an optimal batch. To the best of our knowledge, PPES is the first non-greedy batch Bayesian optimization strategy. We demonstrate the benefit of this approach in optimization performance on both synthetic and real world applications, including problems in machine learning, rocket science and robotics."},{"id":3,"title":"Sandwiching the marginal likelihood using bidirectional Monte Carlo","url":"https://www.researchgate.net/publication/283658712_Sandwiching_the_marginal_likelihood_using_bidirectional_Monte_Carlo","abstraction":"Computing the marginal likelihood (ML) of a model requires marginalizing out all of the parameters and latent variables, a difficult high-dimensional summation or integration problem. To make matters worse, it is often hard to measure the accuracy of one's ML estimates. We present bidirectional Monte Carlo, a technique for obtaining accurate log-ML estimates on data simulated from a model. This method obtains stochastic lower bounds on the log-ML using annealed importance sampling or sequential Monte Carlo, and obtains stochastic upper bounds by running these same algorithms in reverse starting from an exact posterior sample. The true value can be sandwiched between these two stochastic bounds with high probability. Using the ground truth log-ML estimates obtained from our method, we quantitatively evaluate a wide variety of existing ML estimators on several latent variable models: clustering, a low rank approximation, and a binary attributes model. These experiments yield insights into how to accurately estimate marginal likelihoods."},{"id":4,"title":"Dirichlet Fragmentation Processes","url":"https://www.researchgate.net/publication/281895707_Dirichlet_Fragmentation_Processes","abstraction":"Tree structures are ubiquitous in data across many domains, and many datasets are naturally modelled by unobserved tree structures. In this paper, first we review the theory of random fragmentation processes [Bertoin, 2006], and a number of existing methods for modelling trees, including the popular nested Chinese restaurant process (nCRP). Then we define a general class of probability distributions over trees: the Dirichlet fragmentation process (DFP) through a novel combination of the theory of Dirichlet processes and random fragmentation processes. This DFP presents a stick-breaking construction, and relates to the nCRP in the same way the Dirichlet process relates to the Chinese restaurant process. Furthermore, we develop a novel hierarchical mixture model with the DFP, and empirically compare the new model to similar models in machine learning. Experiments show the DFP mixture model to be convincingly better than existing state-of-the-art approaches for hierarchical clustering and density modelling."},{"id":5,"title":"Subsampling-Based Approximate Monte Carlo for Discrete Distributions","url":"https://www.researchgate.net/publication/279633530_Subsampling-Based_Approximate_Monte_Carlo_for_Discrete_Distributions","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Drawing a sample from a discrete distribution is one of the building\n <br> components for Monte Carlo methods. Like other sampling algorithms, discrete\n <br> sampling also suffers from high computational burden in large-scale inference\n <br> problems. We study the problem of sampling a discrete random variable with a\n <br> high degree of dependency that is typical in large-scale Bayesian inference and\n <br> graphical models, and propose an efficient approximate solution with a\n <br> subsampling approach. We make a novel connection between the discrete sampling\n <br> and Multi-Armed Bandits problems with a finite reward population and provide\n <br> three algorithms with theoretical guarantees. Empirical evaluations show the\n <br> robustness and efficiency of the approximate algorithms in both synthetic and\n <br> real-world large-scale problems.\n</div> \n<p></p>"},{"id":6,"title":"An Empirical Study of Stochastic Variational Algorithms for the Beta Bernoulli Process","url":"https://www.researchgate.net/publication/279309917_An_Empirical_Study_of_Stochastic_Variational_Algorithms_for_the_Beta_Bernoulli_Process","abstraction":"Stochastic variational inference (SVI) is emerging as the most promising candidate for scaling inference in Bayesian probabilistic models to large datasets. However, the performance of these methods has been assessed primarily in the context of Bayesian topic models, particularly latent Dirichlet allocation (LDA). Deriving several new algorithms, and using synthetic, image and genomic datasets, we investigate whether the understanding gleaned from LDA applies in the setting of sparse latent factor models, specifically beta process factor analysis (BPFA). We demonstrate that the big picture is consistent: using Gibbs sampling within SVI to maintain certain posterior dependencies is extremely effective. However, we find that different posterior dependencies are important in BPFA relative to LDA. Particularly, approximations able to model intra-local variable dependence perform best."},{"id":7,"title":"MCMC for Variationally Sparse Gaussian Processes","url":"https://www.researchgate.net/publication/278332447_MCMC_for_Variationally_Sparse_Gaussian_Processes","abstraction":"Gaussian process (GP) models form a core part of probabilistic machine learning. Considerable research effort has been made into attacking three issues with GP models: how to compute efficiently when the number of data is large; how to approximate the posterior when the likelihood is not Gaussian and how to estimate covariance function parameter posteriors. This paper simultaneously addresses these, using a variational approximation to the posterior which is sparse in support of the function but otherwise free-form. The result is a Hybrid Monte-Carlo sampling scheme which allows for a non-Gaussian approximation over the function values and covariance parameters simultaneously, with efficient computations based on inducing-point sparse GPs. Code to replicate each experiment in this paper will be available shortly."},{"id":8,"title":"A Bayesian approach to constrained single- and multi-objective optimization","url":"https://www.researchgate.net/publication/282570552_A_Bayesian_approach_to_constrained_single-_and_multi-objective_optimization","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n This article addresses the problem of derivative-free (single- or multi-objective) optimization subject to multiple inequality constraints. Both the objective and constraint functions are assumed to be smooth, non-linear and expensive to evaluate. As a consequence, the number of evaluations that can be used to carry out the optimization is very limited, as in complex industrial design optimization problems. The method we propose to overcome this difficulty has its roots in the Bayesian and the multiobjective optimization literatures. More specifically, an extended domination rule is used to handle the constraints and a corresponding Bayesian expected hyper-volume improvement sampling criterion is proposed. This new criterion extends existing Bayesian sampling criteria to the multi-objective constrained case, and makes it possible to start the algorithm without an initial feasible point. The calculation and optimization of the criterion are performed using Sequential Monte Carlo techniques. In particular, an algorithm similar to the subset simulation method, which is well known in the field of structural reliability, is used to estimate the expected hyper-volume improvement criterion. The method, which we call BMOO (for Bayesian Multi-Objective Optimization), is compared to state-of-the-art algorithms for single-objective and multi-objective constrained optimization problems.\n</div> \n<p></p>"},{"id":9,"title":"Variational inference for Dirichlet process mixtures. Bayesian Anal 1:121-144","url":"https://www.researchgate.net/publication/254212736_Variational_inference_for_Dirichlet_process_mixtures_Bayesian_Anal_1121-144","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Dirichlet process (DP) mixture models are the cornerstone of nonparametric Bayesian\n <br> statistics, and the development of Monte-Carlo Markov chain (MCMC) sampling methods for DP\n <br> mixtures has enabled the application of nonparametric Bayesian methods to a variety of\n <br> practical data analysis problems. However, MCMC sampling can be prohibitively slow, and it\n <br> is important to explore alternatives. One class of alternatives is provided by variational\n <br> methods, a class of deterministic algorithms that convert inference problems into\n <br> optimization problems (Opper and Saad 2001; Wainwright and Jordan 2003). Thus far,\n <br> variational methods have mainly been explored in the parametric setting, in particular\n <br> within the formalism of the exponential family (Attias 2000; Ghahramani and Beal 2001;\n <br> Blei et al. 2003). In this paper, we present a variational inference algorithm for DP\n <br> mixtures. We present experiments that compare the algorithm to Gibbs sampling algorithms\n <br> for DP mixtures of Gaussians and present an application to a large-scale image analysis \n <br> problem.\n</div> \n<p></p>"},{"id":10,"title":"Social Signal Processing: Survey of an Emerging Domain","url":"https://www.researchgate.net/publication/222430190_Social_Signal_Processing_Survey_of_an_Emerging_Domain","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n The ability to understand and manage social signals of a person we are communicating with is the core of social intelligence. Social intelligence is a facet of human intelligence that has been argued to be indispensable and perhaps the most important for success in life. This paper argues that next-generation computing needs to include the essence of social intelligence – the ability to recognize human social signals and social behaviours like turn taking, politeness, and disagreement – in order to become more effective and more efficient. Although each one of us understands the importance of social signals in everyday life situations, and in spite of recent advances in machine analysis of relevant behavioural cues like blinks, smiles, crossed arms, laughter, and similar, design and development of automated systems for social signal processing (SSP) are rather difficult. This paper surveys the past efforts in solving these problems by a computer, it summarizes the relevant findings in social psychology, and it proposes a set of recommendations for enabling the development of the next generation of socially aware computing.\n</div> \n<p></p>"},{"id":11,"title":"The Infinite Hidden Markov Random Field Model","url":"https://www.researchgate.net/publication/44572779_The_Infinite_Hidden_Markov_Random_Field_Model","abstraction":"Hidden Markov random field (HMRF) models are widely used for image segmentation, as they appear naturally in problems where a spatially constrained clustering scheme is asked for. A major limitation of HMRF models concerns the automatic selection of the proper number of their states, i.e., the number of region clusters derived by the image segmentation procedure. Existing methods, including likelihood- or entropy-based criteria, and reversible Markov chain Monte Carlo methods, usually tend to yield noisy model size estimates while imposing heavy computational requirements. Recently, Dirichlet process (DP, infinite) mixture models have emerged in the cornerstone of nonparametric Bayesian statistics as promising candidates for clustering applications where the number of clusters is unknown a priori; infinite mixture models based on the original DP or spatially constrained variants of it have been applied in unsupervised image segmentation applications showing promising results. Under this motivation, to resolve the aforementioned issues of HMRF models, in this paper, we introduce a nonparametric Bayesian formulation for the HMRF model, the infinite HMRF model, formulated on the basis of a joint Dirichlet process mixture (DPM) and Markov random field (MRF) construction. We derive an efficient variational Bayesian inference algorithm for the proposed model, and we experimentally demonstrate its advantages over competing methodologies."},{"id":12,"title":"Painful data: The UNBC-McMaster shoulder pain expression archive database","url":"https://www.researchgate.net/publication/221292544_Painful_data_The_UNBC-McMaster_shoulder_pain_expression_archive_database","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n A major factor hindering the deployment of a fully functional automatic facial expression detection system is the lack of representative data. A solution to this is to narrow the context of the target application, so enough data is available to build robust models so high performance can be gained. Automatic pain detection from a patient's face represents one such application. To facilitate this work, researchers at McMaster University and University of Northern British Columbia captured video of participant's faces (who were suffering from shoulder pain) while they were performing a series of active and passive range-of-motion tests to their affected and unaffected limbs on two separate occasions. Each frame of this data was AU coded by certified FACS coders, and self-report and observer measures at the sequence level were taken as well. This database is called the UNBC-McMaster Shoulder Pain Expression Archive Database. To promote and facilitate research into pain and augment current datasets, we have publicly made available a portion of this database which includes: (1) 200 video sequences containing spontaneous facial expressions, (2) 48,398 FACS coded frames, (3) associated pain frame-by-frame scores and sequence-level self-report and observer measures, and (4) 66-point AAM landmarks. This paper documents this data distribution in addition to describing baseline results of our AAM/SVM system. This data will be available for distribution in March 2011.\n</div> \n<p></p>"},{"id":13,"title":"On the Goldstein-Levitin-Polyak gradient projection method","url":"https://www.researchgate.net/publication/224680516_On_the_Goldstein-Levitin-Polyak_gradient_projection_method","abstraction":"This paper considers some aspects of a gradient projection method proposed by Goldstein [1], Levitin and Polyak [3] and more recently, in a less general context, by Mc-Cormick [10]. We propose and analyze some convergent stepsize rules to be used in conjunction with the method. These rules are similar in spirit with the efficient Armijo rule for the method of steepest descent and under mild assumptions they have the desirable property that they identify the set of active inequality constraints in a finite number of iterations. As a result the method may be converted towards the end of the process to a conjugate direction, Quasi-Newton or Newton's method and achieve the attendant superlinear convergence rate. As an example we propose a quadratically convergent combination of the method with Newton's method. Such combined methods appear to be very efficient for large scale problems with many simple constraints such as those often appearing in optimal control."},{"id":14,"title":"OpenEAR - Introducing the Munich open-source emotion and affect recognition toolkit","url":"https://www.researchgate.net/publication/224088060_OpenEAR_-_Introducing_the_Munich_open-source_emotion_and_affect_recognition_toolkit","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Various open-source toolkits exist for speech recognition and speech processing. These toolkits have brought a great benefit to the research community, i.e. speeding up research. Yet, no such freely available toolkit exists for automatic affect recognition from speech. We herein introduce a novel open-source affect and emotion recognition engine, which integrates all necessary components in one highly efficient software package. The components include audio recording and audio file reading, state-of-the-art paralinguistic feature extraction and plugable classification modules. In this paper we introduce the engine and extensive baseline results. Pre-trained models for four affect recognition tasks are included in the openEAR distribution. The engine is tailored for multi-threaded, incremental on-line processing of live input in real-time, however it can also be used for batch processing of databases.\n</div> \n<p></p>"},{"id":15,"title":"Beam sampling for the infinite hidden Markov model","url":"https://www.researchgate.net/publication/221345210_Beam_sampling_for_the_infinite_hidden_Markov_model","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n The innite hidden Markov model is a non- parametric extension of the widely used hid- den Markov model. Our paper introduces a new inference algorithm for the innite Hidden Markov model called beam sam- pling. Beam sampling combines slice sam- pling, which limits the number of states con- sidered at each time step to a nite number, with dynamic programming, which samples whole state trajectories eciently. Our algo- rithm typically outperforms the Gibbs sam- pler and is more robust. We present appli- cations of iHMM inference using the beam sampler on changepoint detection and text prediction problems.\n</div> \n<p></p>"},{"id":16,"title":"Nonparametric Bayesian Image Segmentation","url":"https://www.researchgate.net/publication/225797350_Nonparametric_Bayesian_Image_Segmentation","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Image segmentation algorithms partition the set of pixels of an image into a specific number of different, spatially homogeneous\n <br> groups. We propose a nonparametric Bayesian model for histogram clustering which automatically determines the number of segments\n <br> when spatial smoothness constraints on the class assignments are enforced by a Markov Random Field. A Dirichlet process prior\n <br> controls the level of resolution which corresponds to the number of clusters in data with a unique cluster structure. The resulting posterior is efficiently\n <br> sampled by a variant of a conjugate-case sampling algorithm for Dirichlet process mixture models. Experimental results are\n <br> provided for real-world gray value images, synthetic aperture radar images and magnetic resonance imaging data.\n</div> \n<p></p>"},{"id":17,"title":"An HDP-HMM for systems with state persistence","url":"https://www.researchgate.net/publication/221344933_An_HDP-HMM_for_systems_with_state_persistence","abstraction":"The hierarchical Dirichlet process hidden Markov model (HDP-HMM) is a flexible, nonparametric model which allows state spaces of unknown size to be learned from data. We demonstrate some limitations of the original HDP-HMM formulation (Teh et al., 2006), and propose a sticky exten- sion which allows more robust learning of smoothly varying dynamics. Using DP mix- tures, this formulation also allows learning of more complex, multimodal emission dis- tributions. We further develop a sampling algorithm that employs a truncated approx- imation of the DP to jointly resample the full state sequence, greatly improving mixing rates. Via extensive experiments with syn- thetic data and the NIST speaker diarization database, we demonstrate the advantages of our sticky extension, and the utility of the HDP-HMM in real-world applications."},{"id":18,"title":"Infinite Hidden Conditional Random Fields for Human Behavior Analysis","url":"https://www.researchgate.net/publication/260353896_Infinite_Hidden_Conditional_Random_Fields_for_Human_Behavior_Analysis","abstraction":"Hidden conditional random fields (HCRFs) are discriminative latent variable models that have been shown to successfully learn the hidden structure of a given classification problem (provided an appropriate validation of the number of hidden states). In this brief, we present the infinite HCRF (iHCRF), which is a nonparametric model based on hierarchical Dirichlet processes and is capable of automatically learning the optimal number of hidden states for a classification task. We show how we learn the model hyperparameters with an effective Markov-chain Monte Carlo sampling technique, and we explain the process that underlines our iHCRF model with the Restaurant Franchise Rating Agencies analogy. We show that the iHCRF is able to converge to a correct number of represented hidden states, and outperforms the best finite HCRFs-chosen via cross-validation-for the difficult tasks of recognizing instances of agreement, disagreement, and pain. Moreover, the iHCRF manages to achieve this performance in significantly less total training, validation, and testing time."},{"id":19,"title":"Bayesian Cluster Analysis","url":"https://www.researchgate.net/publication/31002185_Bayesian_Cluster_Analysis","abstraction":"SUMMARY A parametric model for partitioning individuals into mutually exclusive groups is given. A Bayesian analysis is applied and a loss structure imposed. A model-dependent definition of a similarity matrix is proposed and estimates based on this matrix are justified in a decision-theoretic framework. Some existing cluster analysis techniques are derived as special limiting cases. The results of the procedure applied to two data sets are compared with other analyses."},{"id":20,"title":"An Improved Criterion for Clustering Based on the Posterior Similarity Matrix","url":"https://www.researchgate.net/publication/241251898_An_Improved_Criterion_for_Clustering_Based_on_the_Posterior_Similarity_Matrix","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n In this paper we address the problem of choosing a single clustering estimate ^c based on an MCMC sample of clusterings c(1);c(2) :::;c(M) from the posterior distribution of a Bayesian cluster model. Methods to derive ^c based on the posterior similarity matrix, a matrix with entries P(ci = cjjy), the posterior probabilities that the observations i and j are in the same cluster, are reviewed and discussed. Minimization of a com- monly used loss function for this purpose by Binder (1978) is shown to be equivalent to maximizing the Rand index between estimated and true clustering. We propose a new criterion for choosing an estimated cluster- ing, the posterior expected adjusted Rand index with the true clustering, which outperforms Binder's loss, MAP and an ad hoc criterion in a sim- ulation study. An application to Fisher's Iris data is also provided. Keywords: Adjusted Rand index; Bayesian inference; Cluster analysis; Markov chain Monte Carlo; Loss functions.\n</div> \n<p></p>"},{"id":21,"title":"Bayesian cluster analysis: Point estimation and credible balls","url":"https://www.researchgate.net/publication/276296321_Bayesian_cluster_analysis_Point_estimation_and_credible_balls","abstraction":"Clustering is widely studied in statistics and machine learning, with applications in a variety of fields. As opposed to classical algorithms which return a single clustering solution, Bayesian nonparametric models provide a posterior over the entire space of partitions, allowing one to assess statistical properties, such as uncertainty on the number of clusters. However, an important problem is how to summarize the posterior; the huge dimension of partition space and difficulties in visualizing it add to this problem. In a Bayesian analysis, the posterior of a real-valued parameter of interest is often summarized by reporting a point estimate such as the posterior mean along with 95% credible intervals to characterize uncertainty. In this paper, we extend these ideas to develop appropriate point estimates and credible sets to summarize the posterior of clustering structure based on decision and information theoretic techniques."},{"id":22,"title":"Scaling the iHMM: Parallelization versus Hadoop","url":"https://www.researchgate.net/publication/224175402_Scaling_the_iHMM_Parallelization_versus_Hadoop","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n This paper compares parallel and distributed implementations of an iterative, Gibbs sampling, machine learning algorithm. Distributed implementations run under Hadoop on facility computing clouds. The probabilistic model under study is the infinite HMM, in which parameters are learnt using an instance blocked Gibbs sampling, with a step consisting of a dynamic program. We apply this model to learn part-of-speech tags from newswire text in an unsupervised fashion. However our focus here is on runtime performance, as opposed to NLP-relevant scores, embodied by iteration duration, ease of development, deployment and debugging.\n</div> \n<p></p>"},{"id":23,"title":"Bayesian Learning via Stochastic Gradient Langevin Dynamics","url":"https://www.researchgate.net/publication/221346425_Bayesian_Learning_via_Stochastic_Gradient_Langevin_Dynamics","abstraction":"In this paper we propose a new framework for learning from large scale datasets based on iterative learning from small mini-batches. By adding the right amount of noise to a standard stochastic gradient optimization algorithm we show that the iterates will converge to samples from the true posterior distribution as we anneal the stepsize. This seamless transition between optimization and Bayesian posterior sampling provides an inbuilt protection against overfitting. We also propose a practical method for Monte Carlo estimates of posterior statistics which monitors a “sampling threshold ” and collects samples after it has been surpassed. We apply the method to three models: a mixture of Gaussians, logistic regression and ICA with natural gradients. 1."},{"id":24,"title":"Austerity in MCMC Land: Cutting the Metropolis-Hastings Budget","url":"https://www.researchgate.net/publication/236235190_Austerity_in_MCMC_Land_Cutting_the_Metropolis-Hastings_Budget","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Can we make Bayesian posterior MCMC sampling more efficient when faced with\n <br> very large datasets? We argue that computing the likelihood for N datapoints\n <br> twice in order to reach a single binary decision is computationally\n <br> inefficient. We introduce an approximate Metropolis-Hastings rule based on a\n <br> sequential hypothesis test which allows us to accept or reject samples with\n <br> high confidence using only a fraction of the data required for the exact MH\n <br> rule. While this introduces an asymptotic bias, we show that this bias can be\n <br> controlled and is more than offset by a decrease in variance due to our ability\n <br> to draw more samples per unit of time. We show that the same idea can also be\n <br> applied to Gibbs sampling in densely connected graphs.\n</div> \n<p></p>"},{"id":25,"title":"Concentration inequalities for sampling without replacement","url":"https://www.researchgate.net/publication/256606492_Concentration_inequalities_for_sampling_without_replacement","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Concentration inequalities quantify the deviation of a random variable from a\n <br> fixed value. In spite of numerous applications, such as opinion surveys or\n <br> ecological counting procedures, few concentration results are known for the\n <br> setting of sampling without replacement from a finite population. Until now,\n <br> the best general concentration inequality has been a Hoeffding inequality due\n <br> to Serfling (1974). In this paper, we first improve on the fundamental result\n <br> of Serfling (1974), and further extend it to obtain a Bernstein concentration\n <br> bound for sampling without replacement. We then derive an empirical version of\n <br> our bound that does not require the variance to be known to the user.\n</div> \n<p></p>"},{"id":26,"title":"Monte Carlo MCMC: efficient inference by approximate sampling","url":"https://www.researchgate.net/publication/262350854_Monte_Carlo_MCMC_efficient_inference_by_approximate_sampling","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Conditional random fields and other graphical models have achieved state of the art results in a variety of tasks such as coreference, relation extraction, data integration, and parsing. Increasingly, practitioners are using models with more complex structure---higher tree-width, larger fan-out, more features, and more data---rendering even approximate inference methods such as MCMC inefficient. In this paper we propose an alternative MCMC sampling scheme in which transition probabilities are approximated by sampling from the set of relevant factors. We demonstrate that our method converges more quickly than a traditional MCMC sampler for both marginal and MAP inference. In an author coreference task with over 5 million mentions, we achieve a 13 times speedup over regular MCMC inference.\n</div> \n<p></p>"},{"id":27,"title":"The Tradeoffs of Large Scale Learning.","url":"https://www.researchgate.net/publication/221618614_The_Tradeoffs_of_Large_Scale_Learning","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of small-scale and large-sc ale learning problems. Small-scale learning problems are subject to the usual approximation-estimation tradeoff. Large-scale learning problems are subject to a qualitatively different tradeoff involving the computational complexity of the underlying optimization algorithms in non-trivial ways.\n</div> \n<p></p>"},{"id":28,"title":"Slice sampling mixture models","url":"https://www.researchgate.net/publication/220286498_Slice_sampling_mixture_models","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n We propose a more efficient version of the slice sampler for Dirichlet process mixture models described by Walker (Commun.\n <br> Stat., Simul. Comput. 36:45–54, 2007). This new sampler allows for the fitting of infinite mixture models with a wide-range of prior specifications. To illustrate\n <br> this flexibility we consider priors defined through infinite sequences of independent positive random variables. Two applications\n <br> are considered: density estimation using mixture models and hazard function estimation. In each case we show how the slice\n <br> efficient sampler can be applied to make inference in the models. In the mixture case, two submodels are studied in detail.\n <br> The first one assumes that the positive random variables are Gamma distributed and the second assumes that they are inverse-Gaussian\n <br> distributed. Both priors have two hyperparameters and we consider their effect on the prior distribution of the number of\n <br> occupied clusters in a sample. Extensive computational comparisons with alternative “conditional” simulation techniques for\n <br> mixture models using the standard Dirichlet process prior and our new priors are made. The properties of the new priors are\n <br> illustrated on a density estimation problem.\n</div> \n<p></p>"},{"id":29,"title":"Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation","url":"https://www.researchgate.net/publication/2360567_Hoeffding_Races_Accelerating_Model_Selection_Search_for_Classification_and_Function_Approximation","abstraction":"Selecting a good model of a set of input points by cross validation is a computationally intensive process, especially if the number of possible models or the number of training points is high. Techniques such as gradient descent are helpful in searching through the space of models, but problems such as local minima, and more importantly, lack of a distance metric between various models reduce the applicability of these search methods. Hoeffding Races is a technique for finding a good model for the data by quickly discarding bad models, and concentrating the computational effort at differentiating between the better ones. This paper focuses on the special case of leave-one-out cross validation applied to memorybased learning algorithms, but we also argue that it is applicable to any class of model selection problems. 1 Introduction Model selection addresses \"high level\" decisions about how best to tune learning algorithm architectures for particular tasks. Such decisions include which..."},{"id":30,"title":"lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits","url":"https://www.researchgate.net/publication/259478458_lil%27_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n The paper proposes a novel upper confidence bound (UCB) procedure for\n <br> identifying the arm with the largest mean in a multi-armed bandit game in the\n <br> fixed confidence setting using a small number of total samples. The procedure\n <br> cannot be improved in the sense that the number of samples required to identify\n <br> the best arm is within a constant factor of a lower bound based on the law of\n <br> the iterated logarithm (LIL). Inspired by the LIL, we construct our confidence\n <br> bounds to explicitly account for the infinite time horizon of the algorithm. In\n <br> addition, by using a novel stopping time for the algorithm we avoid a union\n <br> bound over the arms that has been observed in other UCB-type algorithms. We\n <br> prove that the algorithm is optimal up to constants and also show through\n <br> simulations that it provides superior performance with respect to the\n <br> state-of-the-art.\n</div> \n<p></p>"},{"id":31,"title":"Probability Inequalities for the Sum in Sampling without Replacement","url":"https://www.researchgate.net/publication/38357750_Probability_Inequalities_for_the_Sum_in_Sampling_without_Replacement","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Upper bounds are established for the probability that, in sampling without replacement from a finite population, the sample sum exceeds its expected value by a specified amount. These are obtained as corollaries of two main results. Firstly, a useful upper bound is derived for the moment generating function of the sum, leading to an exponential probability inequality and related moment inequalities. Secondly, maximal inequalities are obtained, extending Kolmogorov's inequality and the Hajek-Renyi inequality. Compared to sampling with replacement, the results incorporate sharpenings reflecting the influence of the sampling fraction, $n/N$, where $n$ denotes the sample size and $N$ the population size. We go somewhat beyond previous work by Hoeffding (1963) and Sen (1970). As in the latter reference, martingale techniques are exploited. Applications to simple linear rank statistics are noted, dealing with the two-sample Wilcoxon statistic as an example. Finally, the question of sharpness of the exponential bounds is considered.\n</div> \n<p></p>"},{"id":32,"title":"Auto-Encoding Variational Bayes","url":"https://www.researchgate.net/publication/259400035_Auto-Encoding_Variational_Bayes","abstraction":"Can we efficiently learn the parameters of directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and in case of large datasets? We introduce a novel learning and approximate inference method that works efficiently, under some mild conditions, even in the on-line and intractable case. The method involves optimization of a stochastic objective function that can be straightforwardly optimized w.r.t. all parameters, using standard gradient-based optimization methods. The method does not require the typically expensive sampling loops per datapoint required for Monte Carlo EM, and all parameter updates correspond to optimization of the variational lower bound of the marginal likelihood, unlike the wake-sleep algorithm. These theoretical advantages are reflected in experimental results."},{"id":33,"title":"Infinite Sparse Factor Analysis and Infinite Independent Components Analysis","url":"https://www.researchgate.net/publication/220848162_Infinite_Sparse_Factor_Analysis_and_Infinite_Independent_Components_Analysis","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n A nonparametric Bayesian extension of Independent Components Analysis (ICA) is proposed where observed data Y is modelled as a linear superposition, G, of a potentially infinite number of hidden sources, X. Whether a given source is active for a specific data point is specified by an infinite binary matrix, Z. The resulting sparse representation allows increased data reduction compared to standard ICA. We define a prior on Z using the Indian Buffet Process (IBP). We describe four variants of the model, with Gaussian or Laplacian priors on X and the one or two-parameter IBPs. We demonstrate Bayesian inference under these models using a Markov Chain Monte Carlo (MCMC) algorithm on synthetic and gene expression data and compare to standard ICA algorithms.\n</div> \n<p></p>"},{"id":34,"title":"Fixed-Form Variational Posterior Approximation through Stochastic Linear Regression","url":"https://www.researchgate.net/publication/228083473_Fixed-Form_Variational_Posterior_Approximation_through_Stochastic_Linear_Regression","abstraction":"We propose a general algorithm for approximating nonstandard Bayesian posterior distributions. The algorithm minimizes the Kullback-Leibler divergence of an approximating distribution to the intractable posterior distribution. Our method can be used to approximate any posterior distribution, provided that it is given in closed form up to the proportionality constant. The approximation can be any distribution in the exponential family or any mixture of such distributions, which means that it can be made arbitrarily precise. Several examples illustrate the speed and accuracy of our approximation method in practice."},{"id":35,"title":"Variational Inference for Bayesian Mixtures of Factor Analysers","url":"https://www.researchgate.net/publication/2239690_Variational_Inference_for_Bayesian_Mixtures_of_Factor_Analysers","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n We present an algorithm that infers the model structure of a mixture of factor analysers using an ecient and deterministic variational approximation to full Bayesian integration over model parameters. This procedure can automatically determine the optimal number of components and the local dimensionality of each component (i.e. the number of factors in each factor analyser). Alternatively it can be used to infer posterior distributions over number of components and dimensionalities. Since all parameters are integrated out the method is not prone to over tting. Using a stochastic procedure for adding components it is possible to perform the variational optimisation incrementally and to avoid local maxima. Results show that the method works very well in practice and correctly infers the number and dimensionality of nontrivial synthetic examples. By importance sampling from the variational approximation we show how to obtain unbiased estimates of the true evidence, the exa...\n</div> \n<p></p>"},{"id":36,"title":"Sparse Stochastic Inference for Latent Dirichlet allocation","url":"https://www.researchgate.net/publication/228095627_Sparse_Stochastic_Inference_for_Latent_Dirichlet_allocation","abstraction":"We present a hybrid algorithm for Bayesian topic models that combines the efficiency of sparse Gibbs sampling with the scalability of online stochastic inference. We used our algorithm to analyze a corpus of 1.2 million books (33 billion words) with thousands of topics. Our approach reduces the bias of variational inference and generalizes to many Bayesian hidden-variable models."},{"id":37,"title":"Nonparametric Bayes Estimators Based on Beta Processes in Models for Life History Data","url":"https://www.researchgate.net/publication/38359431_Nonparametric_Bayes_Estimators_Based_on_Beta_Processes_in_Models_for_Life_History_Data","abstraction":"Several authors have constructed nonparametric Bayes estimators for a cumulative distribution function based on (possibly right-censored) data. The prior distributions have, for example, been Dirichlet processes or, more generally, processes neutral to the right. The present article studies the related problem of finding Bayes estimators for cumulative hazard rates and related quantities, w.r.t. prior distributions that correspond to cumulative hazard rate processes with nonnegative independent increments. A particular class of prior processes, termed beta processes, is introduced and is shown to constitute a conjugate class. To arrive at these, a nonparametric time-discrete framework for survival data, which has some independent interest, is studied first. An important bonus of the approach based on cumulative hazards is that more complicated models for life history data than the simple life table situation can be treated, for example, time-inhomogeneous Markov chains. We find posterior distributions and derive Bayes estimators in such models and also present a semiparametric Bayesian analysis of the Cox regression model. The Bayes estimators are easy to interpret and easy to compute. In the limiting case of a vague prior the Bayes solution for a cumulative hazard is the Nelson-Aalen estimator and the Bayes solution for a survival probability is the Kaplan-Meier estimator."},{"id":38,"title":"Infinite Latent Feature Models and the Indian Buffet Process","url":"https://www.researchgate.net/publication/220270203_Infinite_Latent_Feature_Models_and_the_Indian_Buffet_Process","abstraction":"We define a probability distribution over equivalence classes of binary ma- trices with a finite number of rows and an unbounded number of columns. This distribution is suitable for use as a prior in probabilistic models that represent objects using a potentially infinite array of features. We derive the distribution by taking the limit of a distribution over N × K binary matrices as K ! 1, a strategy inspired by the derivation of the Chinese restaurant process (Aldous, 1985; Pitman, 2002) as the limit of a Dirichlet-multinomial model. This strategy preserves the exchangeability of the rows of matrices. We define several simple generative processes that result in the same distri- bution over equivalence classes of binary matrices, one of which we call the Indian buffet process. We illustrate the use of this distribution as a prior in an infinite latent feature model, deriving a Markov chain Monte Carlo algo- rithm for inference in this model and applying this algorithm to an artificial dataset."},{"id":39,"title":"Natural Gradient Works Efficiently in Learning","url":"https://www.researchgate.net/publication/2433873_Natural_Gradient_Works_Efficiently_in_Learning","abstraction":"When a parameter space has a certain underlying structure, the ordinary gradient of a function does not represent its steepest direction, but the natural graadient does. Information geometry is used for calculating the natural gradients in the parameter space of perceptrons, the space of matrices (for blind source separation), and the space of linear dynamical systems (for blind source deconvolution). The dynamical behaviour of natural gradient online learning is analyzed and is proved to be Fischer efficient, implying that it has assymptotically the same performance as the optimal batch estimation of parameters. This suggests that the plateau phenomenon, which appears in the backpropagation learning algorithm of multilayer perceptrons, might disappear or might not be so serious when the natural gradient is used. An adaptive method of updating the learning rate is proposed and analyzed."},{"id":40,"title":"Estimating Mixture of Dirichlet Process Models","url":"https://www.researchgate.net/publication/2468788_Estimating_Mixture_of_Dirichlet_Process_Models","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Current Gibbs sampling schemes in mixture of Dirichlet process (MDP) models are restricted to using \"conjugate\" base measures which allow analytic evaluation of the transition probabilities when resampling configurations, or alternatively need to rely on approximate numeric evaluations of some transition probabilities. Implementation of Gibbs sampling in more general MDP models is an open and important problem since most applications call for the use of non-conjugate base measures. In this paper we propose a conceptual framework for computational strategies. This framework provides a perspective on current methods, facilitates comparisons between them, and leads to several new methods that expand the scope of MDP models to non-conjugate situations. We discuss one in detail. The basic strategy is based on expanding the parameter vector, and is applicable for MDP models with arbitrary base measure and likelihood. Strategies are also presented for the important class of normal-normal MDP ...\n</div> \n<p></p>"},{"id":41,"title":"Sparse On-Line Gaussian Processes","url":"https://www.researchgate.net/publication/11500673_Sparse_On-Line_Gaussian_Processes","abstraction":"We develop an approach for sparse representations of gaussian process (GP) models (which are Bayesian types of kernel machines) in order to overcome their limitations for large data sets. The method is based on a combination of a Bayesian on-line algorithm, together with a sequential construction of a relevant subsample of the data that fully specifies the prediction of the GP model. By using an appealing parameterization and projection techniques in a reproducing kernel Hilbert space, recursions for the effective parameters and a sparse gaussian approximation of the posterior process are obtained. This allows for both a propagation of predictions and Bayesian error measures. The significance and robustness of our approach are demonstrated on a variety of experiments."},{"id":42,"title":"Bayesian Filtering and Smoothing","url":"https://www.researchgate.net/publication/259390620_Bayesian_Filtering_and_Smoothing","abstraction":"Filtering and smoothing methods are used to produce an accurate estimate of the state of a time-varying system based on multiple observational inputs (data). Interest in these methods has exploded in recent years, with numerous applications emerging in fields such as navigation, aerospace engineering, telecommunications and medicine. This compact, informal introduction for graduate students and advanced undergraduates presents the current state-of-the-art filtering and smoothing methods in a unified Bayesian framework. Readers learn what non-linear Kalman filters and particle filters are, how they are related, and their relative advantages and disadvantages. They also discover how state-of-the-art Bayesian parameter estimation methods can be combined with state-of-the-art filtering and smoothing algorithms. The book's practical and algorithmic approach assumes only modest mathematical prerequisites. Examples include Matlab computations, and the numerous end-of-chapter exercises include computational assignments. Matlab code is available for download at www.cambridge.org/sarkka, promoting hands-on work with the methods."},{"id":43,"title":"A comparative evaluation of stochastic-based inference methods for Gaussian process models","url":"https://www.researchgate.net/publication/257618460_A_comparative_evaluation_of_stochastic-based_inference_methods_for_Gaussian_process_models","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Gaussian Process (GP) models are extensively used in data analysis given their flexible modeling capabilities and interpretability. The fully Bayesian treatment of GP models is analytically intractable, and therefore it is necessary to resort to either deterministic or stochastic approximations. This paper focuses on stochastic-based inference techniques. After discussing the challenges associated with the fully Bayesian treatment of GP models, a number of inference strategies based on Markov chain Monte Carlo methods are presented and rigorously assessed. In particular, strategies based on efficient parameterizations and efficient proposal mechanisms are extensively compared on simulated and real data on the basis of convergence speed, sampling efficiency, and computational cost.\n</div> \n<p></p>"},{"id":44,"title":"Variational Inference for Gaussian Process Modulated Poisson Processes","url":"https://www.researchgate.net/publication/267759656_Variational_Inference_for_Gaussian_Process_Modulated_Poisson_Processes","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n We present the first fully variational Bayesian inference scheme for\n <br> continuous Gaussian-process-modulated Poisson processes. Such point processes\n <br> are used in a variety of domains, including neuroscience, geo-statistics and\n <br> astronomy, but their use is hindered by the computational cost of existing\n <br> inference schemes. Our scheme: requires no discretisation of the domain; scales\n <br> linearly in the number of observed events; and is many orders of magnitude\n <br> faster than previous sampling based approaches. The resulting algorithm is\n <br> shown to outperform standard methods on synthetic examples, coal mining\n <br> disaster data and in the prediction of Malaria incidences in Kenya.\n</div> \n<p></p>"},{"id":45,"title":"Scalable Variational Gaussian Process Classification","url":"https://www.researchgate.net/publication/268079368_Scalable_Variational_Gaussian_Process_Classification","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Gaussian process classification is a popular method with a number of\n <br> appealing properties. We show how to scale the model within a variational\n <br> inducing point framework, outperforming the state of the art on benchmark\n <br> datasets. Importantly, the variational formulation can be exploited to allow\n <br> classification in problems with millions of data points, as we demonstrate in\n <br> experiments.\n</div> \n<p></p>"},{"id":46,"title":"A Unifying View of Sparse Approximate Gaussian Process Regression","url":"https://www.researchgate.net/publication/41781406_A_Unifying_View_of_Sparse_Approximate_Gaussian_Process_Regression","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n We provide a new unifying view, including all existing proper probabilistic sparse approximations for Gaussian process regression. Our approach relies on expressing the effective prior which the methods are using. This allows new insights to be gained, and highlights the relationship between existing methods. It also allows for a clear theoretically justified ranking of the closeness of the known approximations to the corresponding full GPs. Finally we point directly to designs of new better sparse approximations, combining the best of the existing strategies, within attractive computational constraints.\n</div> \n<p></p>"},{"id":47,"title":"Scaling Limits for the Transient Phase of Local Metropolis-Hastings Algorithms","url":"https://www.researchgate.net/publication/2834582_Scaling_Limits_for_the_Transient_Phase_of_Local_Metropolis-Hastings_Algorithms","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n This paper considers high-dimensional Metropolis and Langevin algorithms in their initial transient phase. In stationarity, these algorithms are well-understood and it is now well-known how to scale their proposal distribution variances. For the random walk Metropolis algorithm, convergence during the transient phase is extremely regular - to the extent that the algorithm's sample path actually resembles a deterministic trajectory. In contrast, the Langevin algorithm with variance scaled to be optimal for stationarity, performs rather erratically. We give weak convergence results which explain both of these types of behaviour, and give practical guidance on implementation based on our theory.\n</div> \n<p></p>"},{"id":48,"title":"Log Gaussian Cox Processes","url":"https://www.researchgate.net/publication/227701452_Log_Gaussian_Cox_Processes","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Planar Cox processes directed by a log Gaussian intensity process are investigated in the univariate and multivariate cases. The appealing properties of such models are demonstrated theoretically as well as through data examples and simulations. In particular, the first, second and third-order properties are studied and utilized in the statistical analysis of clustered point patterns. Also empirical Bayesian inference for the underlying intensity surface is considered.\n</div> \n<p></p>"}]}