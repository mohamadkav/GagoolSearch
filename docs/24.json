{"id":24,"title":"Austerity in MCMC Land: Cutting the Metropolis-Hastings Budget","url":"https://www.researchgate.net/publication/236235190_Austerity_in_MCMC_Land_Cutting_the_Metropolis-Hastings_Budget","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Can we make Bayesian posterior MCMC sampling more efficient when faced with\n <br> very large datasets? We argue that computing the likelihood for N datapoints\n <br> twice in order to reach a single binary decision is computationally\n <br> inefficient. We introduce an approximate Metropolis-Hastings rule based on a\n <br> sequential hypothesis test which allows us to accept or reject samples with\n <br> high confidence using only a fraction of the data required for the exact MH\n <br> rule. While this introduces an asymptotic bias, we show that this bias can be\n <br> controlled and is more than offset by a decrease in variance due to our ability\n <br> to draw more samples per unit of time. We show that the same idea can also be\n <br> applied to Gibbs sampling in densely connected graphs.\n</div> \n<p></p>"}