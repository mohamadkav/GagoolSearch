{"id":286,"title":"Approximations of Markov Chains and High-Dimensional Bayesian Inference","url":"https://www.researchgate.net/publication/281058916_Approximations_of_Markov_Chains_and_High-Dimensional_Bayesian_Inference","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n The Markov Chain Monte Carlo method is the dominant paradigm for posterior\n <br> computation in Bayesian analysis. It has long been common to control\n <br> computation time by making approximations to the Markov transition kernel.\n <br> Comparatively little attention has been paid to convergence and estimation\n <br> error in these approximating Markov Chains. We propose a framework for\n <br> assessing when to use approximations in MCMC algorithms, and how much error in\n <br> the transition kernel should be tolerated to obtain optimal estimation\n <br> performance with respect to a specified loss function and computational budget.\n <br> The results require only ergodicity of the exact kernel and control of the\n <br> kernel approximation accuracy. The theoretical framework is applied to\n <br> approximations based on random subsets of data, low-rank approximations of\n <br> Gaussian processes, and a novel approximating Markov chain for discrete mixture\n <br> models.\n</div> \n<p></p>"}