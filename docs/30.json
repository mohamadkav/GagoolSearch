{"id":30,"title":"lil' UCB : An Optimal Exploration Algorithm for Multi-Armed Bandits","url":"https://www.researchgate.net/publication/259478458_lil%27_UCB_An_Optimal_Exploration_Algorithm_for_Multi-Armed_Bandits","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n The paper proposes a novel upper confidence bound (UCB) procedure for\n <br> identifying the arm with the largest mean in a multi-armed bandit game in the\n <br> fixed confidence setting using a small number of total samples. The procedure\n <br> cannot be improved in the sense that the number of samples required to identify\n <br> the best arm is within a constant factor of a lower bound based on the law of\n <br> the iterated logarithm (LIL). Inspired by the LIL, we construct our confidence\n <br> bounds to explicitly account for the infinite time horizon of the algorithm. In\n <br> addition, by using a novel stopping time for the algorithm we avoid a union\n <br> bound over the arms that has been observed in other UCB-type algorithms. We\n <br> prove that the algorithm is optimal up to constants and also show through\n <br> simulations that it provides superior performance with respect to the\n <br> state-of-the-art.\n</div> \n<p></p>"}