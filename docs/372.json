{"id":372,"title":"Lower Bounds on the Sample Complexity of Exploration in the Multi-armed Bandit Problem","url":"https://www.researchgate.net/publication/221497401_Lower_Bounds_on_the_Sample_Complexity_of_Exploration_in_the_Multi-armed_Bandit_Problem","abstraction":"We consider the Multi-armed bandit problem under the PAC (\"probably approximately correct\") model. It was shown by Even-Dar et al. (5) that given n arms, it suces to play the arms a total of O (n=\"2)log(1=-) times to find an \"-optimal arm with probability of at least 1¡-. Our contribution is a matching lower bound that holds for any sampling policy. We also generalize the lower bound to a Bayesian setting, and to the case where the statistics of the arms are known but the identities of the arms are not."}