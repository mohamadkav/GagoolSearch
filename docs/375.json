{"id":375,"title":"Unimodal Bandits without Smoothness","url":"https://www.researchgate.net/publication/263545276_Unimodal_Bandits_without_Smoothness","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n We consider stochastic bandit problems with a continuum set of arms and where\n <br> the expected reward is a continuous and unimodal function of the arm. No\n <br> further assumption is made regarding the smoothness and the structure of the\n <br> expected reward function. We propose Stochastic Pentachotomy (SP), an algorithm\n <br> for which we derive finite-time regret upper bounds. In particular, we show\n <br> that, for any expected reward function $\\mu$ that behaves as\n <br> $\\mu(x)=\\mu(x^\\star)-C|x-x^\\star|^\\xi$ locally around its maximizer $x^\\star$\n <br> for some $\\xi, C&gt;0$, the SP algorithm is order-optimal, i.e., its regret scales\n <br> as $O(\\sqrt{T\\log(T)})$ when the time horizon $T$ grows large. This regret\n <br> scaling is achieved without the knowledge of $\\xi$ and $C$. Our algorithm is\n <br> based on asymptotically optimal sequential statistical tests used to\n <br> successively prune an interval that contains the best arm with high\n <br> probability. To our knowledge, the SP algorithm constitutes the first\n <br> sequential arm selection rule that achieves a regret scaling as $O(\\sqrt{T})$\n <br> up to a logarithmic factor for non-smooth expected reward functions, as well as\n <br> for smooth functions with unknown smoothness.\n</div> \n<p></p>"}