{"id":378,"title":"Ordinal optimization - empirical large deviations rate estimators, and stochastic multi-armed bandits","url":"https://www.researchgate.net/publication/280104102_Ordinal_optimization_-_empirical_large_deviations_rate_estimators_and_stochastic_multi-armed_bandits","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Consider the ordinal optimization problem of finding a population amongst\n <br> many with the smallest mean when these means are unknown but population samples\n <br> can be generated via simulation. Typically, by selecting a population with the\n <br> smallest sample mean, it can be shown that the false selection probability\n <br> decays at an exponential rate. Lately researchers have sought algorithms that\n <br> guarantee that this probability is restricted to a small $\\delta$ in order\n <br> $\\log(1/\\delta)$ computational time by estimating the associated large\n <br> deviations rate function via simulation. We show that such guarantees are\n <br> misleading. Enroute, we identify the large deviations principle followed by the\n <br> empirically estimated large deviations rate function that may also be of\n <br> independent interest. Further, we show a negative result that when populations\n <br> have unbounded support, any policy that asymptotically identifies the correct\n <br> population with probability at least $1-\\delta$ for each problem instance\n <br> requires more than $O(\\log(1/\\delta))$ samples in making such a determination\n <br> in any problem instance. This suggests that some restrictions are essential on\n <br> populations to devise $O(\\log(1/\\delta))$ algorithms with $1 - \\delta$\n <br> correctness guarantees. We note that under restriction on population moments,\n <br> such methods are easily designed. We also observe that sequential methods from\n <br> stochastic multi-armed bandit literature can be adapted to devise such\n <br> algorithms.\n</div> \n<p></p>"}