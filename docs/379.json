{"id":379,"title":"Optimally Confident UCB : Improved Regret for Finite-Armed Bandits","url":"https://www.researchgate.net/publication/280590277_Optimally_Confident_UCB_Improved_Regret_for_Finite-Armed_Bandits","abstraction":"I present the first algorithm for stochastic finite-armed bandits that simultaneously enjoys order-optimal problem-dependent regret and worst-case regret. The algorithm is based on UCB, but with a carefully chosen confidence parameter that optimally balances the risk of failing confidence intervals against the cost of excessive optimism. A brief empirical evaluation suggests the new algorithm is at least competitive with Thompson sampling."}