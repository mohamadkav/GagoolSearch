{"id":383,"title":"Monte Carlo Non-Local Means: Random Sampling for Large-Scale Image Filtering","url":"https://www.researchgate.net/publication/259483032_Monte_Carlo_Non-Local_Means_Random_Sampling_for_Large-Scale_Image_Filtering","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n We propose a randomized version of the non-local means (NLM) algorithm for\n <br> large-scale image filtering. The new algorithm, called Monte Carlo non-local\n <br> means (MCNLM), speeds up the classical NLM by computing a small subset of image\n <br> patch distances, which are randomly selected according to a designed sampling\n <br> pattern. We make two contributions. First, we analyze the performance of the\n <br> MCNLM algorithm and show that, for large images or large external image\n <br> databases, the random outcomes of MCNLM are tightly concentrated around the\n <br> deterministic full NLM result. In particular, our error probability bounds show\n <br> that, at any given sampling ratio, the probability for MCNLM to have a large\n <br> deviation from the original NLM solution decays exponentially as the size of\n <br> the image or database grows. Second, we derive explicit formulas for optimal\n <br> sampling patterns that minimize the error probability bound by exploiting\n <br> partial knowledge of the pairwise similarity weights. Numerical experiments\n <br> show that MCNLM is competitive with other state-of-the-art fast NLM algorithms\n <br> for single-image denoising. When applied to denoising images using an external\n <br> database containing ten billion patches, MCNLM returns a randomized solution\n <br> that is within 0.2 dB of the full NLM solution while reducing the runtime by\n <br> three orders of magnitude.\n</div> \n<p></p>"}