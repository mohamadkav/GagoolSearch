{"id":391,"title":"Variational Auto-encoded Deep Gaussian Processes","url":"https://www.researchgate.net/publication/284476380_Variational_Auto-encoded_Deep_Gaussian_Processes","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n We develop a scalable deep non-parametric generative model by augmenting deep\n <br> Gaussian processes with a recognition model. Inference is performed in a novel\n <br> scalable variational framework where the variational posterior distributions\n <br> are reparametrized through a multilayer perceptron. The key aspect of this\n <br> reformulation is that it prevents the proliferation of variational parameters\n <br> which otherwise grow linearly in proportion to the sample size. We derive a new\n <br> formulation of the variational lower bound that allows us to distribute most of\n <br> the computation in a way that enables to handle datasets of the size of\n <br> mainstream deep learning tasks. We show the efficacy of the method on a variety\n <br> of challenges including deep unsupervised learning and deep Bayesian\n <br> optimization.\n</div> \n<p></p>"}