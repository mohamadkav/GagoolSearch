{"id":395,"title":"The Variational Fair Auto Encoder","url":"https://www.researchgate.net/publication/283532090_The_Variational_Fair_Auto_Encoder","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n We investigate the problem of learning representations that are invariant to\n <br> certain nuisance or sensitive factors of variation in the data while retaining\n <br> as much of the remaining information as possible. Our model is based on a\n <br> variational auto-encoding architecture with priors that encourage independence\n <br> between sensitive and latent factors of variation. Any subsequent processing,\n <br> such as classification, can then be performed on this purged latent\n <br> representation. To remove any remaining dependencies we incorporate an\n <br> additional penalty term based on the ``Maximum Mean Discrepancy'' (MMD)\n <br> measure. We discuss how these architectures can be efficiently trained on data\n <br> and show in experiments that this method is more effective than previous work\n <br> in removing unwanted sources of variation while maintaining informative latent\n <br> representations.\n</div> \n<p></p>"}