{"id":398,"title":"When crowds hold privileges: Bayesian unsupervised representation learning with oracle constraints","url":"https://www.researchgate.net/publication/278733876_When_crowds_hold_privileges_Bayesian_unsupervised_representation_learning_with_oracle_constraints","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Representation learning systems typically rely on massive amounts of labeled\n <br> data in order to be trained effectively. Recently, high-dimensional parametric\n <br> models like convolutional neural networks have succeeded in building rich\n <br> representations using either compressive, reconstructive or supervised\n <br> criteria. However, the semantic structure inherent in observations is\n <br> oftentimes lost in the process. Human perception excels at understanding\n <br> semantics but cannot always be expressed in terms of labels. Human-in-the-loop\n <br> systems like crowdsourcing are often employed to generate similarity\n <br> constraints using an implicit similarity function encoded in human perception.\n <br> We propose to combine generative unsupervised feature learning with learning\n <br> from similarity orderings in order to learn models which take advantage of\n <br> privileged information coming from the crowd. We use a fast variational\n <br> algorithm to learn the model on standard datasets and demonstrate applicability\n <br> to two image datasets, where classification is drastically improved. We show\n <br> how triplet-samples of the crowd can supplement labels as a source of\n <br> information to shape latent spaces with rich semantic information.\n</div> \n<p></p>"}