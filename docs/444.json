{"id":444,"title":"Flexible Modeling of Latent Task Structures in Multitask Learning","url":"https://www.researchgate.net/publication/228095688_Flexible_Modeling_of_Latent_Task_Structures_in_Multitask_Learning","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Multitask learning algorithms are typically designed assuming some fixed, a\n <br> priori known latent structure shared by all the tasks. However, it is usually\n <br> unclear what type of latent task structure is the most appropriate for a given\n <br> multitask learning problem. Ideally, the \"right\" latent task structure should\n <br> be learned in a data-driven manner. We present a flexible, nonparametric\n <br> Bayesian model that posits a mixture of factor analyzers structure on the\n <br> tasks. The nonparametric aspect makes the model expressive enough to subsume\n <br> many existing models of latent task structures (e.g, mean-regularized tasks,\n <br> clustered tasks, low-rank or linear/non-linear subspace assumption on tasks,\n <br> etc.). Moreover, it can also learn more general task structures, addressing the\n <br> shortcomings of such models. We present a variational inference algorithm for\n <br> our model. Experimental results on synthetic and real-world datasets, on both\n <br> regression and classification problems, demonstrate the effectiveness of the\n <br> proposed method.\n</div> \n<p></p>"}