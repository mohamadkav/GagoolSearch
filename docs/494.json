{"id":494,"title":"Hessian-Free Optimization For Learning Deep Multidimensional Recurrent Neural Networks","url":"https://www.researchgate.net/publication/281768642_Hessian-Free_Optimization_For_Learning_Deep_Multidimensional_Recurrent_Neural_Networks","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Multidimensional recurrent neural network (MDRNN) has shown a remarkable\n <br> performance in speech and handwriting recognition. The performance of MDRNN is\n <br> improved by further increasing its depth, and the difficulty of learning the\n <br> deeper network is overcome by Hessian-free (HF) optimization. Considering that\n <br> connectionist temporal classification (CTC) is utilized as an objective of\n <br> learning MDRNN for sequence labelling, the non-convexity of CTC poses a problem\n <br> to apply HF to the network. As a solution to this, a convex approximation of\n <br> CTC is formulated and its relationship with the EM algorithm and the Fisher\n <br> information matrix is discussed. MDRNN up to the depth of 15 layers is\n <br> successfully trained using HF, resulting in improved performance for sequence\n <br> labelling.\n</div> \n<p></p>"}