{"id":601,"title":"Optimal scaling for the transient phase of Metropolis Hastings algorithms: The longtime behavior","url":"https://www.researchgate.net/publication/233967527_Optimal_scaling_for_the_transient_phase_of_Metropolis_Hastings_algorithms_The_longtime_behavior","abstraction":"We consider the Random Walk Metropolis algorithm on $\\R^n$ with Gaussian proposals, and when the target probability measure is the $n$-fold product of a one dimensional law. It is well-known (see Roberts et al. (1997))) that, in the limit $n \\to \\infty$, starting at equilibrium and for an appropriate scaling of the variance and of the timescale as a function of the dimension $n$, a diffusive limit is obtained for each component of the Markov chain. In Jourdain et al. (2012), we generalize this result when the initial distribution is not the target probability measure. The obtained diffusive limit is the solution to a stochastic differential equation nonlinear in the sense of McKean. In the present paper, we prove convergence to equilibrium for this equation. We discuss practical counterparts in order to optimize the variance of the proposal distribution to accelerate convergence to equilibrium. Our analysis confirms the interest of the constant acceptance rate strategy (with acceptance rate between 1/4 and 1/3) first suggested in Roberts et al. (1997). We also address scaling of the Metropolis-Adjusted Langevin Algorithm. When starting at equilibrium, a diffusive limit for an optimal scaling of the variance is obtained in Roberts and Rosenthal (1998). In the transient case, we obtain formally that the optimal variance scales very differently in $n$ depending on the sign of a moment of the distribution, which vanishes at equilibrium. This suggest that it is difficult to derive practical recommendations for MALA from such asymptotic results."}