{"id":652,"title":"Bayesian Inference for Gaussian Process Classifiers with Annealing and Exact-Approximate MCMC","url":"https://www.researchgate.net/publication/259010234_Bayesian_Inference_for_Gaussian_Process_Classifiers_with_Annealing_and_Exact-Approximate_MCMC","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n Kernel methods have revolutionized the fields of pattern recognition and\n <br> machine learning. The importance of achieving a sound quantification of\n <br> uncertainty in predictions by characterizing the posterior distribution over\n <br> kernel parameters exactly has been demonstrated in several applications. This\n <br> paper focuses on Markov chain Monte Carlo (MCMC) based inference of covariance\n <br> (kernel) parameters for Gaussian process classifiers. Recently, the\n <br> exact-approximate MCMC approach has been proposed as a practical way to\n <br> efficiently infer covariance parameters in Gaussian process classifiers\n <br> exactly. In this approach, an unbiased estimate of the marginal likelihood\n <br> obtained by importance sampling replaces the actual marginal likelihood in the\n <br> Hastings ratio. This paper presents the application of annealed importance\n <br> sampling to obtain a low-variance unbiased estimate of the marginal likelihood.\n <br> This paper empirically demonstrates that annealed importance sampling reduces\n <br> the variance of the estimate of the marginal likelihood exponentially in the\n <br> number of data compared to importance sampling, while the computational cost\n <br> scales only polynomially. The results on real data demonstrate that employing\n <br> annealed importance sampling in the exact-approximate MCMC approach represents\n <br> a step forward in the development of fully automated exact inference engines\n <br> for Gaussian process classifiers.\n</div> \n<p></p>"}