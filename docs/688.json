{"id":688,"title":"Gradient-based MCMC samplers for Dynamic Causal Modelling","url":"https://www.researchgate.net/publication/280496847_Gradient-based_MCMC_samplers_for_Dynamic_Causal_Modelling","abstraction":"In this technical note we derive two MCMC (Markov Chain Monte Carlo) samplers for dynamic causal models (DCMs). Specifically, we use (a) Hamiltonian MCMC (HMC-E) where sampling is simulated using Hamilton's equation of motion and (b) Langevin Monte Carlo algorithm (LMC-R and LMC-E) that simulates the Langevin diffusion of samples using gradients either on a Euclidean (E) or on a Riemannian (R) manifold. Whilst LMC-R requires minimal tuning, the implementation of HMC-E is heavily dependent on its tuning parameters. These parameters are therefore optimised by learning a Gaussian Process model of the time normalised sample correlation matrix. This allows one to formulate an objective function that balances tuning parameter exploration and exploitation, furnishing an intervention-free inference scheme. Using, neural mass models (NMMs) - a class of biophysically motivated DCMs - we find that HMC-E is statistically more efficient than LMC-R (with a Riemannian metric); yet both gradient-based samplers are far superior to the random walk Metropolis algorithm, which proves inadequate to steer away from dynamical instability. Copyright © 2015. Published by Elsevier Inc."}