{"id":89,"title":"Varying Social Cue Constellations Results in Different Attributed Social Signals in a Simulated Surveillance Task","url":"https://www.researchgate.net/publication/275952718_Varying_Social_Cue_Constellations_Results_in_Different_Attributed_Social_Signals_in_a_Simulated_Surveillance_Task","abstraction":"<p itemprop=\"description\"> <strong>ABSTRACT</strong> </p>\n<div>\n A better understanding of human mental states in social contexts holds the potential to pave the way for implementation of robotic systems capable of more natural and intuitive interaction. In working toward such a goal, this paper reports on a study examining human perception of social signals based on manipulated sets of social cues in a simulated socio-cultural environment. Participants were presented with video vignettes of a simulated marketplace environment in which they took the perspective of an observing robot and were asked to make mental state attributions of a human avatar based on the avatar's expression of a range of social cues. Results indicated that subtly varying combinations of social cues led to participants' perception of different social signals. The different mental state attributions made were also significantly associated with what participants considered an appropriate behavioral response for the robot to exhibit in relation to the avatar. We discuss these results in the context of the development of computational-based perceptual systems to be implemented in socially intelligent robots.\n</div> \n<p></p>"}