{"id":907,"title":"Detecting Duplicates in a Homicide Registry Using a Bayesian Partitioning Approach","url":"https://www.researchgate.net/publication/264425113_Detecting_Duplicates_in_a_Homicide_Registry_Using_a_Bayesian_Partitioning_Approach","abstraction":"Finding duplicates in homicide registries is an important step in keeping an accurate account of lethal violence. This task is not trivial when unique identifiers of the individuals are not available, and it is especially challenging when records are subject to errors and missing values. Traditional approaches to duplicate detection output independent decisions on the coreference status of each pair of records, which often leads to non-transitive decisions that have to be reconciled in some ad-hoc fashion. The task of finding duplicate records in a datafile can be alternatively posed as partitioning the datafile into groups of coreferent records. We present an approach that targets this partition of the file as the parameter of interest, thereby ensuring transitive decisions. Our Bayesian implementation allows us to incorporate prior information on the reliability of the fields in the datafile, which is especially useful when no training data are available, and it also provides a proper account of the uncertainty in the duplicate detection decisions. We present a study to detect killings that were reported multiple times to the United Nations Truth Commission for El Salvador."}