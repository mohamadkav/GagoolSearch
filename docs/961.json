{"id":961,"title":"A multimodal framework for recognizing emotional feedback in conversational recommender systems","url":"https://www.researchgate.net/publication/285245147_A_multimodal_framework_for_recognizing_emotional_feedback_in_conversational_recommender_systems","abstraction":"A conversational recommender system should interactively assist users in order to understand their needs and preferences and produce personalized recommendations accordingly. While traditional recommender systems use a single-shot approach, the conversational ones refine their suggestions during the conversation since they gain more knowledge about the user. This approach can be useful in case the recommender is embodied in a conversational agent acting as a shopping assistant in a smart retail context. In this case, knowledge about the user preferences may be acquired during the conversation and by observing the user behavior. In such a setting, besides \"rational\" information, the agent may grasp information also about extra-rational factors such as attitudes, emotions, likes and dislikes. This paper describes the study performed in order to develop a multimodal framework for recognizing the shopping attitude of the user during the interaction with DIVA, a Dress-shopping InteractiVe Assistant. In particular, speech prosody, gestures and facial expressions have been taken into account for providing feedback to the system and refining the recommendation accordingly."}